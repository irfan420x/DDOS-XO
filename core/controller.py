# Path: core/controller.py
import asyncio
import yaml
import os
from typing import Dict, Any, Optional
from llm.router import LLMRouter
from security.permission_engine import PermissionEngine
from memory.memory_manager import MemoryManager

class LunaController:
    """
    The central brain of LUNA-ULTRA. Coordinates all modules and agents.
    """
    def __init__(self, config_path: str = "config/config.yaml"):
        self.config_path = config_path
        self.config = self.load_config()
        self.llm_router = LLMRouter(self.config.get('llm', {}))
        self.permission_engine = PermissionEngine(self.config.get('permissions', {}))
        self.memory_manager = MemoryManager(self.config.get('memory', {}))
        self.state = "idle"
        self.current_task = None
        self.system_prompt = self.load_system_prompt()

    def load_config(self) -> Dict[str, Any]:
        try:
            with open(self.config_path, 'r') as f:
                return yaml.safe_load(f)
        except FileNotFoundError:
            return {}

    def load_system_prompt(self) -> str:
        prompt_path = "config/system_prompt.txt"
        if os.path.exists(prompt_path):
            with open(prompt_path, 'r') as f:
                return f.read()
        return "You are LUNA-ULTRA, a professional AI agent."

    async def process_input(self, user_input: str) -> str:
        """
        Main entry point for user interaction.
        """
        self.state = "thinking"
        
        # 1. Retrieve context from memory
        context = self.memory_manager.get_context(user_input)
        
        # 2. Build full prompt
        full_prompt = f"Context: {context}\nUser: {user_input}"
        
        # 3. Get response from LLM
        response = await self.llm_router.generate_response(full_prompt, self.system_prompt)
        
        # 4. Store interaction in memory
        self.memory_manager.store_interaction(user_input, response)
        
        self.state = "idle"
        return response

    def get_status(self) -> Dict[str, Any]:
        return {
            "state": self.state,
            "permission": self.permission_engine.current_level.name,
            "provider": self.llm_router.default_provider,
            "user": self.config.get('user', {}).get('name', 'IRFAN')
        }

class Orchestrator:
    """
    Manages complex multi-agent tasks.
    """
    def __init__(self, controller: LunaController):
        self.controller = controller
        self.agents = {} # To be populated with agent instances

    async def execute_plan(self, plan: List[Dict[str, Any]]):
        """
        Executes a multi-step plan generated by the LLM.
        """
        results = []
        for step in plan:
            agent_name = step.get('agent')
            action = step.get('action')
            params = step.get('params', {})
            
            if agent_name in self.agents:
                result = await self.agents[agent_name].execute(action, params)
                results.append(result)
            else:
                results.append({"error": f"Agent {agent_name} not found"})
        return results
