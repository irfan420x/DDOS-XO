# Path: core/orchestrator.py
from typing import Dict, Any, List, Optional
import logging
import json
import re

class Orchestrator:
    """
    LUNA-ULTRA Orchestrator: Manages complex multi-agent tasks and coordinates execution.
    """
    def __init__(self, controller: Any):
        self.controller = controller
        self.agents = {}
        self.initialize_agents()

    def initialize_agents(self):
        """
        Dynamically imports and initializes agents based on configuration.
        """
        from agents.code_agent import CodeAgent
        from agents.automation_agent import AutomationAgent
        from agents.screen_agent import ScreenAgent
        from agents.system_agent import SystemAgent
        from agents.dynamic_agent import DynamicAgent # Import DynamicAgent

        # Register agents with their required dependencies
        self.agents["code"] = CodeAgent(self.controller.config, self.controller.llm_router)
        self.agents["automation"] = AutomationAgent(self.controller.config, self.controller.permission_engine)
        self.agents["screen"] = ScreenAgent(self.controller.config, self.controller.permission_engine)
        self.agents["system"] = SystemAgent(self.controller.config)
        self.agents["dynamic"] = DynamicAgent(self.controller.config, self.controller.llm_router, self.controller.permission_engine) # Initialize DynamicAgent
        
        logging.info(f"Orchestrator: Initialized {len(self.agents)} agents.")

    async def execute_plan(self, plan: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Executes a multi-step plan generated by the LLM.
        """
        results = []
        for step in plan:
            agent_name = step.get("agent")
            action = step.get("action")
            params = step.get("params", {})
            
            logging.info(f"Orchestrator: Executing step - Agent: {agent_name}, Action: {action}")
            
            if agent_name in self.agents:
                try:
                    result = await self.agents[agent_name].execute(action, params)
                    results.append({"step": step, "result": result})
                    
                    # Stop if a critical step fails
                    if not result.get("success") and step.get("critical", True):
                        logging.error(f"Orchestrator: Critical failure in step {step}. Aborting plan.")
                        break
                except Exception as e:
                    logging.error(f"Orchestrator: Exception in agent {agent_name}: {str(e)}")
                    results.append({"step": step, "error": str(e)})
                    break
            else:
                logging.error(f"Orchestrator: Agent {agent_name} not found.")
                results.append({"step": step, "error": f"Agent {agent_name} not found"})
                break
                
        return results

    async def handle_task(self, user_input: str) -> Dict[str, Any]:
        """
        High-level task handler: Plan -> Execute -> Report.
        If no specific agent is identified, defer to DynamicAgent.
        """
        logging.info(f"Orchestrator: Handling task: {user_input}")

        # Step 1: Intent Classification
        # Check for simple conversational greetings or pure chat intent
        greetings = ["hi", "hello", "hey", "how are you", "what's up", "good morning", "good afternoon", "good evening", "thank you", "thanks"]
        if user_input.lower().strip() in greetings:
            logging.info("Orchestrator: Intent classified as conversation (greeting).")
            chat_response = await self.controller.llm_router.generate_response(f"Respond to this greeting: {user_input}")
            return {"response": chat_response, "type": "chat"}

        # Step 2: Intent Analysis via LLM to avoid over-aggressive tool usage
        intent_prompt = (
            f"Analyze the following user input and determine if it requires a tool action (running code, terminal commands, automation) or if it's just a conversational query/statement.\n"
            f"User Input: \"{user_input}\"\n"
            f"Respond with only one word: 'ACTION' or 'CHAT'."
        )
        intent_response = await self.controller.llm_router.generate_response(intent_prompt)
        intent = intent_response.strip().upper()
        logging.info(f"Orchestrator: Intent classified by LLM as: {intent}")

        if "CHAT" in intent and "ACTION" not in intent:
            logging.info("Orchestrator: Handling as pure chat.")
            chat_response = await self.controller.llm_router.generate_response(user_input)
            return {"response": chat_response, "type": "chat"}

        # Step 3: Tool Planning (if not a simple conversation)
        plan_prompt = (
            f"User Task: {user_input}\n"
            f"Available Agents: {list(self.agents.keys())}. Prioritize specific agents over dynamic agent if applicable.\n"
            f"Generate a JSON list of steps with 'agent', 'action', and 'params'.\n"
            f"If the task requires running commands or writing code, use the appropriate agent.\n"
            f"If no specific agent can handle the task, use the 'dynamic' agent with action 'generate_and_execute'.\n"
            f"IMPORTANT: If the user input is just a message and DOES NOT require any system action, return an empty list [].\n"
            f"Example for dynamic agent: [{{'agent': 'dynamic', 'action': 'generate_and_execute', 'params': {{'task_description': 'original task', 'available_tools': {{'python': True, 'bash': True}}}}}}]"
        )
        plan_response_str = await self.controller.llm_router.generate_response(plan_prompt)
        
        plan = []
        try:
            json_match = re.search(r"\[.*\]", plan_response_str, re.DOTALL)
            if json_match:
                plan = json.loads(json_match.group(0))
        except json.JSONDecodeError as e:
            logging.error(f"Orchestrator: Plan parsing error: {str(e)}")

        # Execute plan
        if plan:
            logging.info(f"Orchestrator: Executing plan with {len(plan)} steps.")
            execution_results = await self.execute_plan(plan)
            return {"plan": plan, "results": execution_results, "type": "tool_action"}
        else:
            logging.info("Orchestrator: No plan generated. Falling back to chat response.")
            chat_response = await self.controller.llm_router.generate_response(user_input)
            return {"response": chat_response, "type": "chat"}
